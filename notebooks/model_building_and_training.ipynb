{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1bb68a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8083222e",
   "metadata": {},
   "source": [
    "# Task 2: Model Building and Training\n",
    "\n",
    "This notebook covers:\n",
    "- Data preparation and train-test split\n",
    "- Model selection: Logistic Regression and Random Forest\n",
    "- Model training and evaluation on both datasets\n",
    "- Use of appropriate metrics for imbalanced data (AUC-PR, F1-Score, Confusion Matrix)\n",
    "- Model comparison and justification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5f5e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, confusion_matrix, average_precision_score, precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b907368",
   "metadata": {},
   "source": [
    "## Load Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62d4240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the processed features from Task 1\n",
    "fraud_df = pd.read_csv('../data/Fraud_Data.csv')\n",
    "fraud_df = fraud_df.dropna().drop_duplicates()\n",
    "fraud_df['signup_time'] = pd.to_datetime(fraud_df['signup_time'])\n",
    "fraud_df['purchase_time'] = pd.to_datetime(fraud_df['purchase_time'])\n",
    "fraud_df['age'] = fraud_df['age'].astype(int)\n",
    "fraud_df['hour_of_day'] = fraud_df['purchase_time'].dt.hour\n",
    "fraud_df['day_of_week'] = fraud_df['purchase_time'].dt.dayofweek\n",
    "fraud_df['time_since_signup'] = (fraud_df['purchase_time'] - fraud_df['signup_time']).dt.total_seconds() / 3600\n",
    "user_freq = fraud_df.groupby('user_id').size().rename('transaction_count')\n",
    "fraud_df = fraud_df.merge(user_freq, on='user_id')\n",
    "drop_cols = ['class', 'ip_address', 'signup_time', 'purchase_time', 'user_id', 'device_id']\n",
    "X_fraud = fraud_df.drop(drop_cols, axis=1)\n",
    "y_fraud = fraud_df['class']\n",
    "categorical = ['source', 'browser', 'sex']\n",
    "X_fraud = pd.get_dummies(X_fraud, columns=categorical, drop_first=True)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_fraud_scaled = scaler.fit_transform(X_fraud)\n",
    "Xf_train, Xf_test, yf_train, yf_test = train_test_split(X_fraud_scaled, y_fraud, test_size=0.2, random_state=42, stratify=y_fraud)\n",
    "\n",
    "# Credit card data\n",
    "cc_df = pd.read_csv('../data/creditcard.csv')\n",
    "cc_df = cc_df.dropna().drop_duplicates()\n",
    "X_cc = cc_df.drop('Class', axis=1)\n",
    "y_cc = cc_df['Class']\n",
    "scaler_cc = StandardScaler()\n",
    "X_cc_scaled = scaler_cc.fit_transform(X_cc)\n",
    "Xc_train, Xc_test, yc_train, yc_test = train_test_split(X_cc_scaled, y_cc, test_size=0.2, random_state=42, stratify=y_cc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280d7807",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fc3981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, X_train, y_train, X_test, y_test, model_name=\"Model\"):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:,1] if hasattr(model, \"predict_proba\") else None\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    aucpr = average_precision_score(y_test, y_proba) if y_proba is not None else None\n",
    "\n",
    "    print(f\"=== {model_name} ===\")\n",
    "    print(\"F1-score:\", f1)\n",
    "    if aucpr is not None:\n",
    "        print(\"AUC-PR:\", aucpr)\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "    if y_proba is not None:\n",
    "        precision, recall, _ = precision_recall_curve(y_test, y_proba)\n",
    "        plt.plot(recall, precision)\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.title(f'Precision-Recall Curve: {model_name}')\n",
    "        plt.show()\n",
    "    print()\n",
    "    return f1, aucpr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5342941c",
   "metadata": {},
   "source": [
    "## Train and Evaluate on E-commerce Fraud Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5aa49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "lr_fraud = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42)\n",
    "f1_lr_fraud, aucpr_lr_fraud = train_and_evaluate(lr_fraud, Xf_train, yf_train, Xf_test, yf_test, \"Logistic Regression (Fraud_Data)\")\n",
    "\n",
    "# Random Forest\n",
    "rf_fraud = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)\n",
    "f1_rf_fraud, aucpr_rf_fraud = train_and_evaluate(rf_fraud, Xf_train, yf_train, Xf_test, yf_test, \"Random Forest (Fraud_Data)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c899261",
   "metadata": {},
   "source": [
    "## Train and Evaluate on Credit Card Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7273198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "lr_cc = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42)\n",
    "f1_lr_cc, aucpr_lr_cc = train_and_evaluate(lr_cc, Xc_train, yc_train, Xc_test, yc_test, \"Logistic Regression (CreditCard)\")\n",
    "\n",
    "# Random Forest\n",
    "rf_cc = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)\n",
    "f1_rf_cc, aucpr_rf_cc = train_and_evaluate(rf_cc, Xc_train, yc_train, Xc_test, yc_test, \"Random Forest (CreditCard)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ebf017",
   "metadata": {},
   "source": [
    "## Model Comparison and Justification\n",
    "\n",
    "We compare the F1-score and AUC-PR for both models on both datasets.  \n",
    "Generally, the Random Forest model is expected to outperform Logistic Regression on both datasets due to its ability to capture non-linear relationships and interactions.  \n",
    "However, Logistic Regression remains a strong, interpretable baseline.\n",
    "\n",
    "**Best Model Justification:**  \n",
    "- If Random Forest achieves higher F1-score and AUC-PR, it is preferred for deployment.\n",
    "- If interpretability is critical, Logistic Regression may be chosen despite lower performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ea690f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\n",
    "    \"Dataset\": [\"Fraud_Data\", \"Fraud_Data\", \"CreditCard\", \"CreditCard\"],\n",
    "    \"Model\": [\"Logistic Regression\", \"Random Forest\", \"Logistic Regression\", \"Random Forest\"],\n",
    "    \"F1-score\": [f1_lr_fraud, f1_rf_fraud, f1_lr_cc, f1_rf_cc],\n",
    "    \"AUC-PR\": [aucpr_lr_fraud, aucpr_rf_fraud, aucpr_lr_cc, aucpr_rf_cc]\n",
    "})\n",
    "display(results)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
